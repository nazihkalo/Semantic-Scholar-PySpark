{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "#Graph network imports\n",
    "from graphframes import *\n",
    "from pyspark import *\n",
    "from pyspark.sql import *\n",
    "import numpy as np\n",
    "from pyspark.ml.linalg import *\n",
    "from pyspark.ml.linalg import *\n",
    "from pyspark.sql.types import * \n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "from pyspark.sql.functions import udf #user defined function\n",
    "from pyspark.sql.types import * #Import types == IntegerType, StringType etc.\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statements\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#create Spark session\n",
    "spark = SparkSession.builder.enableHiveSupport().appName('Final_project_read_write').getOrCreate()\n",
    "\n",
    "conf = spark.sparkContext._conf.setAll([('spark.executor.memory', '15g'), ('spark.app.name', 'Final_project_read_write'), ('spark.executor.cores', '10'), ('spark.cores.max', '10'), ('spark.driver.memory','20g')])\n",
    "\n",
    "#print spark configuration settings\n",
    "#spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_data = spark.read.parquet('modeling_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      " |-- inCitations_count: integer (nullable = true)\n",
      " |-- outCitations_count: integer (nullable = true)\n",
      " |-- abstract_wcount: integer (nullable = true)\n",
      " |-- title_wcount: integer (nullable = true)\n",
      " |-- abstract_tfidf: vector (nullable = true)\n",
      " |-- title_tfidf: vector (nullable = true)\n",
      " |-- SJR: string (nullable = true)\n",
      " |-- author_count: integer (nullable = true)\n",
      " |-- fieldsOfStudyVec: vector (nullable = true)\n",
      " |-- sourcesVec: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modeling_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192481"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeling_data.count() - modeling_data.dropna().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+-----------------+------------------+---------------+------------+--------------+--------------------+---+------------+-----------------+-------------+\n",
      "|                  id|year|inCitations_count|outCitations_count|abstract_wcount|title_wcount|abstract_tfidf|         title_tfidf|SJR|author_count| fieldsOfStudyVec|   sourcesVec|\n",
      "+--------------------+----+-----------------+------------------+---------------+------------+--------------+--------------------+---+------------+-----------------+-------------+\n",
      "|57d4efa8939189a64...|null|                0|                 0|              0|          12|(262144,[],[])|(262144,[2196,954...|124|           1|(2179,[12],[1.0])|(4,[0],[1.0])|\n",
      "|5c1c3f390fd575dd1...|null|                0|                 0|              0|          12|(262144,[],[])|(262144,[13957,21...|124|           1| (2179,[9],[1.0])|(4,[0],[1.0])|\n",
      "|c8351f487ab3c8caf...|null|                0|                 0|              0|           2|(262144,[],[])|(262144,[118386,1...|124|           1| (2179,[1],[1.0])|(4,[0],[1.0])|\n",
      "|ebfbc538015eae0c2...|null|                0|                 0|              0|          11|(262144,[],[])|(262144,[30312,31...|124|           1|(2179,[13],[1.0])|(4,[0],[1.0])|\n",
      "|1f9fa4f86cca29555...|null|                0|                 0|              0|           4|(262144,[],[])|(262144,[18448,18...|124|           4| (2179,[0],[1.0])|(4,[0],[1.0])|\n",
      "+--------------------+----+-----------------+------------------+---------------+------------+--------------+--------------------+---+------------+-----------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as f\n",
    "from functools import reduce\n",
    "\n",
    "modeling_data.where(reduce(lambda x, y: x | y, (f.col(x).isNull() for x in modeling_data.columns))).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>192481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inCitations_count</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outCitations_count</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abstract_wcount</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_wcount</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abstract_tfidf</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_tfidf</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SJR</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author_count</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fieldsOfStudyVec</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sourcesVec</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0\n",
       "id                       0\n",
       "year                192481\n",
       "inCitations_count        0\n",
       "outCitations_count       0\n",
       "abstract_wcount          0\n",
       "title_wcount             0\n",
       "abstract_tfidf           0\n",
       "title_tfidf              0\n",
       "SJR                      0\n",
       "author_count             0\n",
       "fieldsOfStudyVec         0\n",
       "sourcesVec               0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "\n",
    "modeling_data.select([count(when(col(c).isNull(), c)).alias(c) for c in modeling_data.columns]).toPandas().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_stats = modeling_data.select('year').summary()\n",
    "median_year = int(year_stats.collect()[5].year)\n",
    "print('the median year is = ', median_year)\n",
    "\n",
    "#Impute median year\n",
    "modeling_data = modeling_data.na.fill({'year': median_year})\n",
    "\n",
    "#Convert to integer type column\n",
    "modeling_data = modeling_data.withColumn(\"year\", modeling_data[\"year\"].cast(IntegerType()))\n",
    "modeling_data = modeling_data.withColumn(\"SJR\", modeling_data[\"SJR\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "#gather feature vector and identify features\n",
    "assembler = VectorAssembler(inputCols = ['year', 'outCitations_count','abstract_wcount','title_wcount','abstract_tfidf',\\\n",
    "                                         'title_tfidf','SJR','author_count','fieldsOfStudyVec', 'sourcesVec'],\n",
    "                            outputCol = 'features', handleInvalid='skip')\n",
    "\n",
    "\n",
    "modeling_data = assembler.transform(modeling_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+--------------------+\n",
      "|                  id|inCitations_count|            features|\n",
      "+--------------------+-----------------+--------------------+\n",
      "|000011af6d4e69b95...|                0|(526477,[0,3,2949...|\n",
      "+--------------------+-----------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#split data into train and test\n",
    "train_df, test_df = modeling_data.select('id','inCitations_count', 'features').randomSplit([0.8, 0.2], seed=42)\n",
    "train_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Length =  7470695\n",
      "Test Length =  1864404\n"
     ]
    }
   ],
   "source": [
    "print('Train Length = ', train_df.count())\n",
    "print('Test Length = ', test_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "#Elastic Net\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol='inCitations_count', regParam=0.3, maxIter=10)\n",
    "lrm = lr.fit(train_df)\n",
    "\n",
    "#coefficients\n",
    "print(\"Coefficients: \" + str(lrm.coefficients))\n",
    "print(\"Intercept: \" + str(lrm.intercept))\n",
    "\n",
    "#model summary\n",
    "print(\"RMSE: %f\" % lrm.summary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % lrm.summary.r2)\n",
    "\n",
    "#p-values are not provided in this model for the solver being used\n",
    "#print(\"pValues: \" + str(lrm.summary.pValues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 30.617903\n",
      "r2: 0.067576\n"
     ]
    }
   ],
   "source": [
    "#model summary\n",
    "print(\"RMSE: %f\" % lrm.summary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % lrm.summary.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions\n",
    "predictions = lrm.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "attrs = sorted(\n",
    "    (attr[\"idx\"], attr[\"name\"]) for attr in (chain(*predictions\n",
    "        .schema[lrm.summary.featuresCol]\n",
    "        .metadata[\"ml_attr\"][\"attrs\"].values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "526477"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 25.949\n",
      "MSE: 673.376\n",
      "MAE: 5.579\n",
      "r2: -0.013\n"
     ]
    }
   ],
   "source": [
    "#[(name, lrm.summary.pValues[idx]) for idx, name in attrs]\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "eval = RegressionEvaluator(labelCol=\"inCitations_count\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "# Root Mean Square Error\n",
    "rmse = eval.evaluate(predictions)\n",
    "print(\"RMSE: %.3f\" % rmse)\n",
    "\n",
    "# Mean Square Error\n",
    "mse = eval.evaluate(predictions, {eval.metricName: \"mse\"})\n",
    "print(\"MSE: %.3f\" % mse)\n",
    "\n",
    "# Mean Absolute Error\n",
    "mae = eval.evaluate(predictions, {eval.metricName: \"mae\"})\n",
    "print(\"MAE: %.3f\" % mae)\n",
    "\n",
    "# r2 - coefficient of determination\n",
    "r2 = eval.evaluate(predictions, {eval.metricName: \"r2\"})\n",
    "print(\"r2: %.3f\" %r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "\n",
    "# Set parameters for the Random Forest.\n",
    "rfr = RandomForestRegressor(maxDepth=5, numTrees=20, labelCol=\"inCitations_count\", predictionCol=\"prediction\")\n",
    "\n",
    "# Fit the model to the data.\n",
    "rfrm = rfr.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a dataset, predict each point's label, and show the results.\n",
    "predictions = rfcm.transform(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: Build a feature importance selector\n",
    "Reference:\n",
    "https://www.timlrx.com/2018/06/19/feature-selection-using-feature-importance-score-creating-a-pyspark-estimator/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark 4G 8e",
   "language": "python",
   "name": "pyspark2_4g8e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
